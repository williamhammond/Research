
1.) We don't need to restrict ourselves to the l1/l2 norm, l2 can be generalized
    to lp, where lp is dependent on how similar our tasks are -Obozinsiki

2.) Multitask methods are useful when features are complex and difficult 
    to induce from limited data - Obozinsiki


TODO:
    Choose how many different patients we are going to use as tasks
    Choose what our starting feature set is
    Deal with optimization problems
    Determine which regularization is best

Questions:
    How do we structure the data? 

    What particular features from the geometry/signal are we going to use? Can we 
    use it in its entiredy or do we need to pick and choose?

    If we're mainly interested in what features are the most pertinent, would we want 
    to use a fixed starting point for all of the patients?

    Are the different number of nodes per heart going to matter?

    Would we treat the signal for each node as a feature? Could we use all these 
    signals then give other features a greater weight?

    How are we going to handle such a large amount of data? Are we going to
    impose restrictions are attempt to change the Malsar code? 
    
    The response variable is the node that was excited correct? 
    
    Is there any domain knowledge we can apply to our regularization techniques?

    Is the focus of this paper the method exclusively trained and tested with 
    actual data, or are we going to train and with simulated and test with 
    actual? Can we do both in the same paper? What should be the focus 
    if we want to get it done before the end of March?

    What is pathwise computation?

References
[Zhou 2012] J. Zhou, J. Chen and J. Ye. MALSAR: Multi-tAsk Learning via StructurAl Regularization. Arizona State University, 2012. http://www.public.asu.edu/~jye02/Software/MALSAR. 
